Lang_URL深度采集程序 v0.98 版本



# 作用

Lang_URL是一款允许自定义网址规则的URL采集程序，在URL采集过程中网址进行动态规则检测，符合条件的网址才会允许记录保存在本地。

# 功能介绍

根据自定义的规则，采集网址的时候对网址的url，标题，内容进行自定义数据筛选。

0.98版本支持挂机无限采集功能
0.98测试版本支持2种原始网址传入方式

	0 导入当前目录下的url.txt
	1 输入关键词采集网址

对传入的url首先进行友链爬行，随后对网址进行动态规则检测，结果自动保存到本地。

# 自定义规则

打开当前目录下的Config.ini，安装需求进行配置

更加详细的使用方法移步 : http://www.langzi.fun/Lang-URL%E8%87%AA%E5%8A%A8%E9%87%87%E9%9B%86.html




# 配置文件作用说明

------------------------------------------------------------------------------------------------

[User]

whoami = Langzi


[Config]

# 条件设置 & 是与关系。| 是或关系。
# 设置成 None 即不检测存在与否关系，直接保存到本地

# 具体用法看下面例子
title = 浪子&博客
# 标题中必须存在【浪子】和【博客】两个词才允许保存到本地
# 如果设置成None的话，不检测标题关系
# 如果设置title = 浪子
# 标题中必须存在【浪子】才允许保存到本地
# title = None 的话，不检测标题中存不存在词
black_title = 捡到钱|踩到屎
# 标题中出现【捡到钱】或【踩到屎】其中任意一个词就排除这个网址
url = www|cn
# 网址中出现【www】或【cn】其中任意一个词就允许保存到本地
black_url = gov.cn|edu.cn
# 网址中出现【gov.cn】或【edu.cn】其中任意一个词就排除这个网址
content = None
# 不检测网页存在与否关系
# 即不管网页存在什么都保存到本地
black_content = 404|360|安全狗
# 网页中出现【404】或【360】或【安全狗】其中任意一个词就排除这个网址
thread = 10
# 采集线程
timeout = 5
# 连接超时5秒
track = 1
# 设置 0 表示对传入的网址不采集友链，直接对传入网址进行动态规则筛选
# 设置 1 将会对传入网址进行友链采集，并且对传入网址和网址的友链进行动态规则筛选
forever = 1
# 对结果重复继续重复爬行友链次数
# 设置 0 表示不会对采集的结果无限重复采集
# 设置 1 会对采集的在进行友链爬行采集一次
# 设置 2 会对采集的在进行友链爬行采集两次
# 设置 3 会对采集的在进行友链爬行采集三次
# 设置 x 会对采集的在进行友链爬行采集x次
# 设置 forever大于0 的前提条件是track=1
white_or = 1 
#设置 white_or = 1 表示所有的白名单(url，title，content中，只要其中一个满足条件就保存到本地，即url = www，title = 国际，content = langzi，只要网址中出现了www就保存到本地)
#设置 white_or = 0 表示所有的白名单(url，title，content中，三个条件都要满足才会保存)

# URL筛选权重比例
# 优先检查 网址黑名单，其次标题黑名单，随后网页黑名单，然后白名单
【** 注意，forever 大于0 的前提条件是track = 1，即必须开启自动爬行友链的前提下才能启用无限采集功能 **】
【** 注意，如果不想采集友链不想多次采集的话，设置forever = 0，track =  0**】
【** 注意，凡是 & | None  都是英文输入法 **】
【** 如果你怕你输入错误了  直接在这里复制进去吧~ **】

&&&&&&

||||||

None None None 

